import sqlite3
import os
import re
import json

db_path = os.path.join(os.path.dirname(__file__), 'python_weekly.db')

def create_table():
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS weekly_summary (
            issue_no INTEGER PRIMARY KEY,
            date TEXT,
            article_count INTEGER,
            project_count INTEGER,
            audio_video_count INTEGER,
            hot_topic_count INTEGER,
            book_count INTEGER
        )
        ''')


def parse_markdown():
    # ä¼˜å…ˆè§£æä¸­æ–‡READMEæ–‡ä»¶
    readme_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'README_ZH.md')
    if not os.path.exists(readme_path):
        readme_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'README.md')
    
    with open(readme_path, 'r', encoding='utf-8') as file:
        content = file.read()
    
    pattern = r'(?<=å¾€æœŸåˆ—è¡¨)(.*?)(?=\n## )'
    section = re.search(pattern, content, re.DOTALL)
    if not section:
        return []
    
    entries = []
    lines = section.group(0).splitlines()
    for i in range(len(lines)):
        issue_date_match = re.match(r'- ç¬¬ (\d+) æœŸï¼š.*?\[(.*?)\]\(.*?(\d{4}-\d{2}-\d{2})-weekly.md\)', lines[i])
        if issue_date_match:
            issue_no = int(issue_date_match.group(1))
            date = issue_date_match.group(3)
            
            # ä»ä¸‹ä¸€è¡Œå¼€å§‹åŒ¹é…æ–‡ç« æ•°ã€å¼€æºé¡¹ç›®æ•°ã€éŸ³è§†é¢‘æ•°ã€çƒ­é—¨è¯é¢˜æ•°ã€èµ ä¹¦æ•°
            if i + 1 < len(lines):
                next_line = lines[i + 1]
                article_count = int(re.search(r'(\d+) ç¯‡', next_line).group(1)) if re.search(r'(\d+) ç¯‡', next_line) else 0
                project_count = int(re.search(r'(\d+) ä¸ªå¼€æº', next_line).group(1)) if re.search(r'(\d+) ä¸ªå¼€æº', next_line) else 0
                
                audio_video_match = re.search(r'(\d+) åˆ™éŸ³|(\d+) åˆ™è§†|(\d+) åˆ™æ’­', next_line)
                if audio_video_match:
                    audio_video_count = int(audio_video_match.group(1) or audio_video_match.group(2) or audio_video_match.group(3) or 0)
                else:
                    audio_video_count = 0
                
                hot_topic_count = int(re.search(r'(\d+) [ä¸ª|åˆ™]çƒ­é—¨', next_line).group(1)) if re.search(r'(\d+) [ä¸ª|åˆ™]çƒ­é—¨', next_line) else 0
                book_count = int(re.search(r'èµ ä¹¦ (\d+) æœ¬', next_line).group(1)) if re.search(r'èµ ä¹¦ (\d+) æœ¬', next_line) else 0
                
                entries.append({
                    'issue_no': issue_no,
                    'date': date,
                    'article_count': article_count,
                    'project_count': project_count,
                    'audio_video_count': audio_video_count,
                    'hot_topic_count': hot_topic_count,
                    'book_count': book_count
                })
    return entries

def insert_into_database(entries):
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        for entry in entries:
            cursor.execute('SELECT issue_no FROM weekly_summary WHERE issue_no = ?', (entry['issue_no'],))
            if cursor.fetchone() is None:
                cursor.execute('''
                INSERT INTO weekly_summary (issue_no, date, article_count, project_count, audio_video_count, hot_topic_count, book_count)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    entry['issue_no'], 
                    entry['date'], 
                    entry.get('article_count', 0),
                    entry.get('project_count', 0), 
                    entry.get('audio_video_count', 0), 
                    entry.get('hot_topic_count', 0),  
                    entry.get('book_count', 0) 
                ))

def print_all_data():
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM weekly_summary')
        rows = cursor.fetchall()
        for row in rows:
            print(f"Issue Number: {row[0]}, Date: {row[1]}, Articles: {row[2]}, Projects: {row[3]}, Audio/Video: {row[4]}, Hot Topics: {row[5]}, Books: {row[6]}")

def get_total_stats():
    """ä»æ•°æ®åº“è·å–å„ç±»åˆ«çš„æ€»æ•°ç»Ÿè®¡"""
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        # è·å–å„ç±»åˆ«æ€»æ•°
        cursor.execute('SELECT SUM(article_count) FROM weekly_summary')
        total_articles = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT SUM(project_count) FROM weekly_summary')
        total_projects = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT SUM(audio_video_count) FROM weekly_summary')
        total_audio_video = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT SUM(hot_topic_count) FROM weekly_summary')
        total_hot_topics = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT SUM(book_count) FROM weekly_summary')
        total_books = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT COUNT(*) FROM weekly_summary')
        total_issues = cursor.fetchone()[0] or 0
        
    return {
        'total_articles': total_articles,
        'total_projects': total_projects,
        'total_audio_video': total_audio_video,
        'total_hot_topics': total_hot_topics,
        'total_books': total_books,
        'total_issues': total_issues
    }

def update_single_readme_stats(readme_path, stats, is_chinese=True):
    """æ›´æ–°å•ä¸ªREADMEæ–‡ä»¶ä¸­çš„ç»Ÿè®¡æ•°æ®"""
    if not os.path.exists(readme_path):
        return False
        
    with open(readme_path, 'r', encoding='utf-8') as file:
        content = file.read()
    
    # ç§»é™¤ç°æœ‰çš„ç»Ÿè®¡æ•°æ®éƒ¨åˆ†ï¼ˆä¸­è‹±æ–‡å…¼å®¹ï¼‰
    stats_pattern = r'## ğŸ“Š æ•°æ®ç»Ÿè®¡.*?(?=\n## |\Z)|## ğŸ“Š Data Statistics.*?(?=\n## |\Z)'
    content = re.sub(stats_pattern, '', content, flags=re.DOTALL)
    
    # åˆ›å»ºç»Ÿè®¡æ•°æ®éƒ¨åˆ†
    if is_chinese:
        stats_section = f"""## ğŸ“Š æ•°æ®ç»Ÿè®¡

<div align="center">

| ğŸ“ˆ ç»Ÿè®¡é¡¹ç›® | ğŸ“Š æ•°é‡ |
|:---:|:---:|
| ğŸ“… **æ€»æœŸæ•°** | **{stats['total_issues']}** æœŸ |
| ğŸ“ **æ€»æ–‡ç« æ•°** | **{stats['total_articles']}** ç¯‡ |
| ğŸš€ **æ€»é¡¹ç›®æ•°** | **{stats['total_projects']}** ä¸ª |
| ğŸµ **æ€»éŸ³è§†é¢‘** | **{stats['total_audio_video']}** åˆ™ |
| ğŸ”¥ **æ€»çƒ­é—¨è¯é¢˜** | **{stats['total_hot_topics']}** ä¸ª |
| ğŸ“š **æ€»èµ ä¹¦** | **{stats['total_books']}** æœ¬ |

</div>

"""
        section_marker = '## ğŸ¦„å¾€æœŸåˆ—è¡¨'
    else:
        stats_section = f"""## ğŸ“Š Data Statistics

<div align="center">

| ğŸ“ˆ Statistics | ğŸ“Š Count |
|:---:|:---:|
| ğŸ“… **Total Issues** | **{stats['total_issues']}** |
| ğŸ“ **Total Articles** | **{stats['total_articles']}** |
| ğŸš€ **Total Projects** | **{stats['total_projects']}** |
| ğŸµ **Total Audio/Video** | **{stats['total_audio_video']}** |
| ğŸ”¥ **Total Hot Topics** | **{stats['total_hot_topics']}** |
| ğŸ“š **Total Books** | **{stats['total_books']}** |

</div>

"""
        section_marker = '## ğŸ¦„ Past Issues'
    
    # åœ¨å¾€æœŸåˆ—è¡¨ä¹‹å‰æ’å…¥ç»Ÿè®¡æ•°æ®
    if section_marker in content:
        content = content.replace(section_marker, stats_section + section_marker)
    else:
        content += '\n' + stats_section
    
    with open(readme_path, 'w', encoding='utf-8') as file:
        file.write(content)
    
    return True

def update_landing_page_stats(stats):
    """æ›´æ–°landing pageçš„ç»Ÿè®¡æ•°æ®JSONæ–‡ä»¶"""
    base_dir = os.path.dirname(os.path.dirname(__file__))
    landing_page_dir = os.path.join(base_dir, 'landing-page')
    
    # æ£€æŸ¥landing-pageç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(landing_page_dir):
        print(f"Landing pageç›®å½•ä¸å­˜åœ¨: {landing_page_dir}")
        return False
    
    # ç”Ÿæˆstats.jsonæ–‡ä»¶è·¯å¾„
    stats_json_path = os.path.join(landing_page_dir, 'public', 'stats.json')
    
    # ç¡®ä¿publicç›®å½•å­˜åœ¨
    public_dir = os.path.dirname(stats_json_path)
    if not os.path.exists(public_dir):
        os.makedirs(public_dir)
    
    # å†™å…¥ç»Ÿè®¡æ•°æ®åˆ°JSONæ–‡ä»¶
    try:
        with open(stats_json_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"Landing pageç»Ÿè®¡æ•°æ®å·²æ›´æ–°: {stats_json_path}")
        return True
    except Exception as e:
        print(f"æ›´æ–°landing pageç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
        return False

def update_readme_stats(stats):
    """æ›´æ–°READMEæ–‡ä»¶ä¸­çš„ç»Ÿè®¡æ•°æ®ï¼Œæ”¯æŒä¸­è‹±æ–‡ä¸¤ä¸ªæ–‡ä»¶"""
    base_dir = os.path.dirname(os.path.dirname(__file__))
    
    # æ›´æ–°ä¸­æ–‡README
    readme_zh_path = os.path.join(base_dir, 'README_ZH.md')
    zh_updated = update_single_readme_stats(readme_zh_path, stats, is_chinese=True)
    
    # æ›´æ–°è‹±æ–‡README
    readme_en_path = os.path.join(base_dir, 'README.md')
    en_updated = update_single_readme_stats(readme_en_path, stats, is_chinese=False)
    
    # è¾“å‡ºæ›´æ–°ç»“æœ
    if zh_updated:
        print(f"README_ZH.md å·²æ›´æ–°ç»Ÿè®¡æ•°æ®")
    if en_updated:
        print(f"README.md å·²æ›´æ–°ç»Ÿè®¡æ•°æ®")
    
    if zh_updated or en_updated:
        print(f"ç»Ÿè®¡æ•°æ®ï¼š")
        print(f"- æ€»æœŸæ•°ï¼š{stats['total_issues']} æœŸ")
        print(f"- æ€»æ–‡ç« æ•°ï¼š{stats['total_articles']} ç¯‡")
        print(f"- æ€»é¡¹ç›®æ•°ï¼š{stats['total_projects']} ä¸ª")
        print(f"- æ€»éŸ³è§†é¢‘ï¼š{stats['total_audio_video']} åˆ™")
        print(f"- æ€»çƒ­é—¨è¯é¢˜ï¼š{stats['total_hot_topics']} ä¸ª")
        print(f"- æ€»èµ ä¹¦ï¼š{stats['total_books']} æœ¬")


def main():
    create_table()
    entries = parse_markdown()
    if entries:
        insert_into_database(entries)
    print_all_data()
    
    # è·å–ç»Ÿè®¡æ•°æ®
    stats = get_total_stats()
    
    # æ›´æ–°READMEç»Ÿè®¡æ•°æ®
    update_readme_stats(stats)
    
    # æ›´æ–°Landing Pageç»Ÿè®¡æ•°æ®
    update_landing_page_stats(stats)

if __name__ == '__main__':
    main()

